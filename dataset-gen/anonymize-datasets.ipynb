{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dir = r'../../data'\n",
    "\n",
    "\n",
    "def list_files(dir):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(dir): \n",
    "        if \"ok\" in os.path.basename(root):\n",
    "            for name in files:\n",
    "                filepath = root + os.sep + name\n",
    "                if filepath.endswith(\".csv\") and \"2021\" in filepath:\n",
    "                    r.append(os.path.join(root, name))\n",
    "                #end if\n",
    "            #end for\n",
    "    #end for\n",
    "    return sorted(r)\n",
    "#end list_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_logs(df_name, weeks_to_keep, truncate_to_week):\n",
    "    df = pd.read_csv(df_name, sep=\",\")\n",
    "    df[\"date\"] = pd.to_datetime(df['Hora'].str.zfill(16), dayfirst=True) #format='%d/%m/%y %H:%M')\n",
    "    #df[\"date\"] = df['date'] - pd.to_timedelta(df['date'].dt.dayofweek, unit='d') if truncate_to_week else df[\"date\"]\n",
    "    #eliminate hours, minutes and seconds\n",
    "    df[\"date\"] = df[\"date\"].dt.date\n",
    "\n",
    "    df[\"key\"] = df[\"Nome completo\"]\n",
    "    #print(\"Unique users found: {}\".format(df.key.nunique()))\n",
    "    \n",
    "    df = df.groupby([df['date'], df[\"key\"]])['Nome do evento'].agg(['count']).reset_index().rename(columns={'count':'count_logs'})\n",
    "\n",
    "    # date, key, count_logs\n",
    "    # date(day), key, count_vpl, count_forum, count_url, count_system, count_page, count_file, count_user_report\n",
    "\n",
    "    df[\"date\"] = pd.to_datetime(df['date'])\n",
    "    #fill count with 0s for all dates seen in the log given that the user has no log in that date\n",
    "    df = df.set_index(['date', 'key']).unstack(fill_value=0).asfreq(\n",
    "        'D', fill_value=0).stack().sort_index(level=1).reset_index()\n",
    "\n",
    "    #get first date and add the offset\n",
    "    thre = df.date.min() + datetime.timedelta(weeks = weeks_to_keep)\n",
    "    #print(df.date.min())\n",
    "    #print(thre)\n",
    "    #filter out weeks out of range\n",
    "    df = df[(df['date'] < thre)]\n",
    "\n",
    "    freqq = \"W\" if truncate_to_week else \"d\"\n",
    "    df = (df.groupby(['key', pd.Grouper(freq=freqq, key='date', closed='left')])\n",
    "            ['count_logs'] #add new columns\n",
    "            .sum()\n",
    "            .unstack(fill_value=0)).reset_index()\n",
    "    df.columns = df.columns.map(str)\n",
    "    col_counter = 1\n",
    "    new_col_names = []\n",
    "    for colname in df.columns:\n",
    "        if colname == \"key\":\n",
    "            new_col_names.append(colname)\n",
    "        else:\n",
    "            new_col_names.append(\"datapoint{}\".format(col_counter))   #gather suffix and append to datapoint-> \"datapoint_\"+colname.substring(\"_\")+\"{}\"\n",
    "            col_counter += 1                                          #datapoint_vpl1, datapoint_url1\n",
    "        #end\n",
    "    #end\n",
    "    df.columns = new_col_names\n",
    "\n",
    "    return df\n",
    "#end process_logs\n",
    "\n",
    "def process_grades(df_name):\n",
    "    df = pd.read_csv(df_name, sep=\",\")\n",
    "    df[\"key\"] = df[\"Nome\"] + \" (\" + df[\"Matrícula\"].astype(str) + \")\"\n",
    "    df[\"target\"] = df[\"Total do curso (Real)\"].replace(\"-\", 0.0).astype(float)\n",
    "    df[\"target_cat\"] = np.where(df['target'] >= 6.0 , 0, 1)\n",
    "    return df[[\"key\", \"target\", \"target_cat\"]]\n",
    "#end process_grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dfs(df_list, weeks_to_keep=10, truncate_to_week=False):\n",
    "    to_concat = []\n",
    "    for i in range(0, len(df_list), 2):\n",
    "        log_first = True if \"logs\" in df_list[i] else False\n",
    "        turma = df_list[i].split(os.sep)[3]\n",
    "        if log_first:\n",
    "            #generate key for logs\n",
    "            #generate key for grades\n",
    "            #merge\n",
    "\n",
    "            #change parameter to both functions to the merged df\n",
    "            df_logs = process_logs(df_list[i], weeks_to_keep, truncate_to_week)\n",
    "            df_grades = process_grades(df_list[i+1])\n",
    "        else:\n",
    "            df_grades = process_grades(df_list[i])\n",
    "            df_logs = process_logs(df_list[i+1], weeks_to_keep, truncate_to_week)\n",
    "        #end if\n",
    "        data_cols = df_logs.columns.tolist()\n",
    "        data_cols.remove(\"key\")\n",
    "        print(\"Logs size = {}\".format(len(df_logs)))\n",
    "        print(\"Grades size = {}\".format(len(df_grades)))\n",
    "        final_df = df_logs.merge(df_grades, on=\"key\", how=\"inner\")\n",
    "\n",
    "        #final_df = final_df.set_index(\"id_group\")\n",
    "\n",
    "        final_df[\"group\"] = turma\n",
    "\n",
    "        #final_df.loc[:, \"id_group\"] = 1\n",
    "        final_df[\"id_group\"] = 1\n",
    "        #final_df.loc[:, \"id_subject\"] = 1\n",
    "        final_df[\"id_subject\"] = 1\n",
    "\n",
    "        #anonymize groups and subjects\n",
    "        final_df.loc[:, \"id_group\"] = final_df.groupby(\"group\").id_group.transform(lambda g: str(uuid.uuid4()))\n",
    "        final_df.loc[:, \"id_subject\"] = final_df.groupby(\"key\").id_subject.transform(lambda g: str(uuid.uuid4()))\n",
    "\n",
    "        ##final_df[\"id_group\"] = final_df.groupby(\"group\").transform(lambda group: str(uuid.uuid4()))\n",
    "        ##final_df[\"id_subject\"] = final_df.groupby(\"key\").transform(lambda group: str(uuid.uuid4()))\n",
    "\n",
    "        to_keep = [\"id_group\", \"id_subject\", \"key\"] + data_cols + [\"target\", \"target_cat\"]\n",
    "        to_concat.append( final_df[to_keep] )\n",
    "    #end for\n",
    "    return pd.concat(to_concat)\n",
    "#end anonymize_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs size = 40\n",
      "Grades size = 26\n",
      "Logs size = 28\n",
      "Grades size = 19\n"
     ]
    }
   ],
   "source": [
    "df_list = list_files(dir)\n",
    "df_final = process_dfs(df_list, weeks_to_keep=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_group</th>\n",
       "      <th>id_subject</th>\n",
       "      <th>key</th>\n",
       "      <th>datapoint1</th>\n",
       "      <th>datapoint2</th>\n",
       "      <th>datapoint3</th>\n",
       "      <th>datapoint4</th>\n",
       "      <th>datapoint5</th>\n",
       "      <th>datapoint6</th>\n",
       "      <th>datapoint7</th>\n",
       "      <th>...</th>\n",
       "      <th>datapoint133</th>\n",
       "      <th>datapoint134</th>\n",
       "      <th>datapoint135</th>\n",
       "      <th>datapoint136</th>\n",
       "      <th>datapoint137</th>\n",
       "      <th>datapoint138</th>\n",
       "      <th>datapoint139</th>\n",
       "      <th>datapoint140</th>\n",
       "      <th>target</th>\n",
       "      <th>target_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>db6ec63e-07e0-4dc6-beb7-604e835da7ac</td>\n",
       "      <td>a5326788-2dd3-4d86-8edc-a321daaf4d92</td>\n",
       "      <td>Andrio Vicente Maguerroski (21105785)</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>db6ec63e-07e0-4dc6-beb7-604e835da7ac</td>\n",
       "      <td>490080fd-d980-4734-b0ae-452627f2d17e</td>\n",
       "      <td>Arthur Paulino Malgarisi Aguiar (21205133)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>db6ec63e-07e0-4dc6-beb7-604e835da7ac</td>\n",
       "      <td>fb83e35f-ec0d-4d42-a468-fd508223798e</td>\n",
       "      <td>Bruna Reginato Bocalon (21200544)</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>db6ec63e-07e0-4dc6-beb7-604e835da7ac</td>\n",
       "      <td>412e5930-a047-42ad-be43-bc2d4ad7de5d</td>\n",
       "      <td>Eduardo Girardi Cesa (21100699)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db6ec63e-07e0-4dc6-beb7-604e835da7ac</td>\n",
       "      <td>8de814e2-600a-4b5a-a5fa-a90f0b967775</td>\n",
       "      <td>Elvio Antonio Lessa (21203900)</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id_group                            id_subject  \\\n",
       "0  db6ec63e-07e0-4dc6-beb7-604e835da7ac  a5326788-2dd3-4d86-8edc-a321daaf4d92   \n",
       "1  db6ec63e-07e0-4dc6-beb7-604e835da7ac  490080fd-d980-4734-b0ae-452627f2d17e   \n",
       "2  db6ec63e-07e0-4dc6-beb7-604e835da7ac  fb83e35f-ec0d-4d42-a468-fd508223798e   \n",
       "3  db6ec63e-07e0-4dc6-beb7-604e835da7ac  412e5930-a047-42ad-be43-bc2d4ad7de5d   \n",
       "4  db6ec63e-07e0-4dc6-beb7-604e835da7ac  8de814e2-600a-4b5a-a5fa-a90f0b967775   \n",
       "\n",
       "                                          key  datapoint1  datapoint2  \\\n",
       "0       Andrio Vicente Maguerroski (21105785)           0          11   \n",
       "1  Arthur Paulino Malgarisi Aguiar (21205133)           0           0   \n",
       "2           Bruna Reginato Bocalon (21200544)           3           4   \n",
       "3             Eduardo Girardi Cesa (21100699)           0           0   \n",
       "4              Elvio Antonio Lessa (21203900)           3           5   \n",
       "\n",
       "   datapoint3  datapoint4  datapoint5  datapoint6  datapoint7  ...  \\\n",
       "0           2           0           0           0           0  ...   \n",
       "1           0           0           0           0           0  ...   \n",
       "2           4           0           0           0           0  ...   \n",
       "3           0           0           0           0           0  ...   \n",
       "4           1           1           1           0           0  ...   \n",
       "\n",
       "   datapoint133  datapoint134  datapoint135  datapoint136  datapoint137  \\\n",
       "0             0             1             0             0             0   \n",
       "1             0             4             4             3             6   \n",
       "2             0            45            25             3             0   \n",
       "3             0             0             0             0             0   \n",
       "4            19            16            10            18            13   \n",
       "\n",
       "   datapoint138  datapoint139  datapoint140  target  target_cat  \n",
       "0             3             1             0     1.5           1  \n",
       "1             0             1            10     7.0           0  \n",
       "2            22             0             0     7.5           0  \n",
       "3             0             0             0     0.0           1  \n",
       "4            15             6             6     9.5           0  \n",
       "\n",
       "[5 rows x 145 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_ts = datetime.datetime.now()\n",
    "today_ts = today_ts.strftime(\"%d-%m-%Y-%H-%M\")\n",
    "\n",
    "df_final.to_csv(\"../../datasets/daily/processed_dataset_{}.csv\".format(today_ts), sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 26)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.query(\"target < 1\").shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb717fa7ade7b467f554cb84e2a26b9935a901a4db8cec015e726017f6f1fad8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
